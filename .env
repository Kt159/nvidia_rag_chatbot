#User's Custom Parameters

# Choose either NVIDIA or AZURE as the host for the models below
MODEL_HOST=NVIDIA

# Choose LLM Model (make sure model is under the selected host)
# E.g meta/llama3-8b-instruct / gpt-35-turbo 
LM_MODEL=meta/llama3-8b-instruct

# Choose Embedding Model (make sure model is under the selected host) 
# E.g. nvidia/nv-embedqa-e5-v5 / text-embedding-ada-002
EMBEDDING_MODEL=nvidia/nv-embedqa-e5-v5

# Output dimensions of the embedding model
EMBEDDING_MODEL_DIMS=1024 

# If using NVIDIA, provide the API key
NVIDIA_API_KEY=<YOUR_API_KEY>


# If using AZURE, provide the API key, endpoint and version
# LLM_API_KEY=<YOUR_API_KEY>
# LLM_ENDPOINT=<YOUR_ENDPOINT>
# LLM_API_VERSION=<YOUR_API_VERSION>



#Default Minio/Milvus Parameters (Set during docker-compose for milvus/minio)

#Minio object storage (Can access GUI at http://localhost:9001)
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET_NAME=test

# Milvus Vector DB
MILVUS_HOST=localhost
MILVUS_PORT=19530
MILVUS_COLLECTION_NAME=test







